{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行环境\n",
    "python 3.6.3\n",
    "\n",
    "Anaconda custom (64-bit)\n",
    "\n",
    "win10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # 矩阵运算\n",
    "import matplotlib.pyplot as plt # 绘图\n",
    "from PIL import Image # 显示图片\n",
    "import struct # 解析dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务定义\n",
    "\n",
    "handwritten digits recognition\n",
    "\n",
    "手写体识别\n",
    "\n",
    "使用全连接的神经网络进行手写体识别\n",
    "\n",
    "加入正则化, dropout, 并且使用random mini batch 加快训练速度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件到数据\n",
    "\n",
    "这里是将文件转为numpy的数组进行表示\n",
    "\n",
    "### 提取图片和标签\n",
    "得到numpy.ndarray表示的数据, shape如下\n",
    "\n",
    "```python\n",
    "trainImage.shape = (60000,28,28)\n",
    "trainLabel.shape = (60000,1)\n",
    "testImage.shape = (10000, 28, 28)\n",
    "testLabel.shape = (10000, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train-images.idx3-ubyte'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b1a8140aea83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train-images.idx3-ubyte'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrainImage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train-labels.idx1-ubyte'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtrainLabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m't10k-images.idx3-ubyte'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train-images.idx3-ubyte'"
     ]
    }
   ],
   "source": [
    "with open('train-images.idx3-ubyte','rb') as f:\n",
    "    trainImage = f.read()\n",
    "with open('train-labels.idx1-ubyte','rb') as f:\n",
    "    trainLabel = f.read()\n",
    "with open('t10k-images.idx3-ubyte','rb') as f:\n",
    "    testImage = f.read()\n",
    "with open('t10k-labels.idx1-ubyte','rb') as f:\n",
    "    testLabel = f.read()\n",
    "\n",
    "# API : struct.unpack(fmt,bytes)\n",
    "\n",
    "# bytes -> (int,int,int,int,numpy.ndarray[])\n",
    "# 接受dataSet原始二进制数据, 返回array, shape为(60000,28,28)\n",
    "def getImageFromMNIST(imageBytes):\n",
    "    assert(type(imageBytes) is bytes),'parameter is no bytes'\n",
    "    magicNum, numOfImages = struct.unpack('>2i',imageBytes[:8]) # 读入校验数据(无用处)和图片数量\n",
    "    rows, columns = struct.unpack('>2i',imageBytes[8:16]) # 读入图片行数和列数\n",
    "    imageSize = rows * columns # 行 * 列 = 图片的规模\n",
    "    # 读入所有图片数据, 总共有 图片规模 * 图片数量 个 unsigned byte\n",
    "    imageTuple = struct.unpack('>'+str(imageSize * numOfImages)+'B',imageBytes[16:])\n",
    "    imageArray = np.array(imageTuple) # 数据类型为默认的int\n",
    "    return imageArray.reshape(numOfImages,rows,columns)\n",
    "\n",
    "def getLabelFromMNIST(labelBytes):\n",
    "    assert(type(labelBytes) is bytes),'parameter is no bytes'\n",
    "    magicNum, numOfLabels = struct.unpack('>2i',labelBytes[:8]) # 读入校验数据(无用处)和标签数量\n",
    "    # 每个标签大小为unsigned byte, 一次读入所有标签\n",
    "    labelSize = 1 * numOfLabels\n",
    "    labelTuple = struct.unpack('>'+str(labelSize)+'B',labelBytes[8:])\n",
    "    labelArray = np.array(labelTuple) \n",
    "    return labelArray.reshape(labelSize,1)\n",
    "\n",
    "trainImage = getImageFromMNIST(trainImage)\n",
    "trainLabel = getLabelFromMNIST(trainLabel)\n",
    "testImage = getImageFromMNIST(testImage)\n",
    "testLabel = getLabelFromMNIST(testLabel)\n",
    "\n",
    "print('trainImage.shape:',trainImage.shape)\n",
    "print('trainLabel.shape:',trainLabel.shape)\n",
    "print('testImage.shape:',testImage.shape)\n",
    "print('testLabel.shape:',testLabel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入数据定义trainImage, trainLabel, testImage, testLabel\n",
    "\n",
    "### 预处理数据\n",
    "$28 \\times 28 = 784$\n",
    "\n",
    "**图片会除以255, 让值落在[0,1]区间上**\n",
    "\n",
    "$$\n",
    "value_i = \\frac {value_i} {\\max(value_i)}\n",
    "$$\n",
    "\n",
    "处理后,\n",
    "```python\n",
    "trainImage.shape = (784, 60000) # (60000, 28, 28) -> (784, 60000)\n",
    "trainLabel.shape = (10, 60000)  # (60000,1) -> (10, 60000)\n",
    "testImage.shape = (784, 10000)  # (10000, 28, 28) -> (784, 10000)\n",
    "testLabel.shape = (10, 10000)   # (10000, 1) -> (10, 10000)\n",
    "```\n",
    "\n",
    "#### 数据含义\n",
    "\n",
    "如英文名, train代表训练集, test代表测试集, Image代表图片数据, Label代表图片标签\n",
    "```python\n",
    "trainImage[:,i]会得到shape = (784,) 的一列数据, 代表一张图片\n",
    "testLabel[:,i]会得到shape = (10,) 的一列数据, 代表一个标签\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (number, 28, 28) -> (784, number)\n",
    "def changeImage(image):\n",
    "    image = image.reshape(-1,28*28)\n",
    "    image = image.T # 转置, 让图片数据变为列表示\n",
    "    image = image.astype(np.float16) # 重置数据类型为numpy.float16\n",
    "    return image / 255.0 # 归一化, 让值落在[0,1]上, 方便训练\n",
    "\n",
    "# (number, 1) -> (10, number)\n",
    "def changeLabel(label):\n",
    "    assert(label.shape[1] == 1)\n",
    "    column = np.arange(10) # get 0~9, shape = (10,)\n",
    "    column = column.reshape(10,1) # to column\n",
    "    return label.T == column # use broadcasting to generate True or False label\n",
    "    \n",
    "trainImage = changeImage(trainImage)\n",
    "trainLabel = changeLabel(trainLabel)\n",
    "testImage = changeImage(testImage)\n",
    "testLabel = changeLabel(testLabel)\n",
    "\n",
    "print('trainImage.shape:',trainImage.shape)\n",
    "print('trainLabel.shape:',trainLabel.shape)\n",
    "print('testImage.shape:',testImage.shape)\n",
    "print('testLabel.shape:',testLabel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法描述\n",
    "\n",
    "### 激活函数\n",
    "\n",
    "隐层都使用Relu激活函数, 输出层使用softmax\n",
    "\n",
    "### 损失函数(使用了交叉熵) (Extra!)\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "对于每个数据, 使用交叉熵, Lost = - \\sum _{j=0} ^{9} y_j \\ln a_j\n",
    "$$\n",
    "\n",
    "* $y_j$ : 实际值, 0或1\n",
    "* $\\ln a_j$ : 激活值(预测值), 小数\n",
    "\n",
    "### L2正则化\n",
    "\n",
    "$$\n",
    "Cost = \\sum _{i=1} ^{m} Lost_i + \\frac {\\lambda} {2} \\sum _ W \\Vert {W} \\Vert ^2\n",
    "$$\n",
    "\n",
    "* $\\lambda$ : L2正则化系数\n",
    "* W : 网络层与网络层之间的权重矩阵\n",
    "\n",
    "\n",
    "### dropout (Extra!)\n",
    "\n",
    "有2个dropout\n",
    "\n",
    "* 在隐层(hidden layers)上的dropout\n",
    "* 在输入层(input layers)上的dropout\n",
    "\n",
    "### random mini batch (Extra!)\n",
    "\n",
    "为了加快训练速度, 使用了随机mini batch\n",
    "\n",
    "可调batch size, 这里使用128的batch size\n",
    "\n",
    "即在每次迭代中, 会从训练集中随机挑选128个样本以及其对应的标签来进行正向传播, 反向传播, 更新参数\n",
    "\n",
    "### 载入自己实现的神经网络模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib # 使用这个可以重新import模块\n",
    "import NN # 自己写的神经网络模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化网络\n",
    "\n",
    "#### 网络层数及数量: 下方cell里的代码\n",
    "\n",
    "#### w和b\n",
    "\n",
    "$w = randn(L_i, L_{i-1}) \\times \\sqrt{\\frac 2 {L_{i-1}}}$\n",
    "\n",
    "$b = 0, shape = (L_i, 1)$\n",
    "\n",
    "* $L_i$ : 第i层网络的节点数量\n",
    "\n",
    "对应代码为\n",
    "\n",
    "```python\n",
    "self.parameters['W'+str(i)] = np.random.randn(layers[i],layers[i-1]) * np.sqrt(2 / layers[i-1])\n",
    "self.parameters['b'+str(i)] = np.zeros((layers[i],1))\n",
    "```\n",
    "\n",
    "#### L2正则化系数$\\lambda = 0.001$\n",
    "\n",
    "#### dropout\n",
    "\n",
    "* 在隐层(hidden layers)上的dropout: 下方代码\n",
    "* 在输入层(input layers)上的dropout: 下方代码\n",
    "\n",
    "#### mini bath size : 128\n",
    "\n",
    "#### 学习率\n",
    "\n",
    "恒定学习率，但是可以停下来，修改学习率后，继续训练\n",
    "\n",
    "手动控制学习率和迭代次数\n",
    "\n",
    "对每次的训练进行多重组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) # 改变随机数种子, 方便复现bug\n",
    "data = { # 训练数据\n",
    "'trainX':trainImage,\n",
    "'trainY':trainLabel\n",
    "}\n",
    "\n",
    "layers = [784,500, 300, 200, 10] # 784代表输入数据规模, layers[i] 代表第 i 层网络的节点数\n",
    "print('layers info:',layers)\n",
    "\n",
    "hy = {\n",
    "    'open-dropout': True,\n",
    "    'dropout': 0.8,\n",
    "    'dropout-input': 0.9\n",
    "}\n",
    "\n",
    "#######################################################\n",
    "\n",
    "relu = lambda z:np.maximum(0.01 * z,z) # Relu 激活函数\n",
    "relu_deriv = lambda z,a:np.where(z > 0,1.0,0.01) # Relu 激活函数的导数\n",
    "\n",
    "def lostFunc(A,Y):\n",
    "    assert(A.shape == Y.shape),'A.shape != Y.shape'\n",
    "    # A and Y are matrix, but we just want to operation on column, so use axis = 0\n",
    "    ylna = np.multiply(Y,np.log(A+1e-10)) # add 1e-10 to forbidden np.log(0)\n",
    "    return -np.sum(ylna,axis = 0,keepdims=True) # remember add minus symbol \"-\"\n",
    "    \n",
    "def softmax(Z): # Z is a column vector, but we need to handle when Z is a matrix, use axis = 0\n",
    "    maxNumber = np.max(Z,axis = 0,keepdims=True)\n",
    "    assert(Z.shape[1] == maxNumber.shape[1])\n",
    "    Z -= maxNumber\n",
    "    Zexp = np.exp(Z)\n",
    "    return Zexp / np.sum(Zexp,axis = 0,keepdims=True)\n",
    "\n",
    "def softmax_deriv(Z,A,Y): # softmax 的导数\n",
    "    assert(A.shape == Y.shape),'A.shape is not same as Y.shape'\n",
    "    return A - Y\n",
    "\n",
    "\n",
    "\n",
    "def getFunction(layers): # 初始化function\n",
    "    function = {\n",
    "                'activation':{},\n",
    "                'derivative':{},\n",
    "                'lostFunction':lostFunc, # lambda a,y:np.sum(np.multiply(-y,np.log(a)),axis = 0), # (AL,Y) -> Lost(AL,Y)\n",
    "                'predictFunction':lambda A:(A,A>=np.max(A,axis = 0)), # (A,preA)\n",
    "                'accuracyFunction':lambda A,Y:1.0/Y.shape[1] * np.sum((np.sum(A==Y,axis = 0,keepdims=True) == 10))\n",
    "                }\n",
    "    L = len(layers) - 1\n",
    "    for i in range(1,L):\n",
    "        function['activation'][i] = relu\n",
    "        function['derivative'][i] = relu_deriv\n",
    "    function['activation'][L] = softmax\n",
    "    function['derivative'][L] = lambda Z,A,Y:softmax_deriv(Z,A,Y)\n",
    "    return function\n",
    "\n",
    "function = getFunction(layers)\n",
    "\n",
    "importlib.reload(NN) # 重新import模块, 便于修改后重新import\n",
    "myNN = NN.NN(data, layers, function, hy) # 初始化网络!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练\n",
    "\n",
    "学习率为`learningRate`, 阶梯式降低\n",
    "\n",
    "batchSize = 128\n",
    "\n",
    "每次的迭代次数不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "costs = myNN.miniBatchRandom(learningRate=0.7,batchSize=128,batchTimes=100,getCost=True)\n",
    "costs = costs + myNN.miniBatchRandom(learningRate=0.4,batchSize=128,batchTimes=100,getCost=True)\n",
    "costs = costs + myNN.miniBatchRandom(learningRate=0.1,batchSize=128,batchTimes=100,getCost=True)\n",
    "costs = costs + myNN.miniBatchRandom(learningRate=0.02,batchSize=128,batchTimes=100,getCost=True)\n",
    "costs = costs + myNN.miniBatchRandom(learningRate=0.0001,batchSize=128,batchTimes=200,getCost=True)\n",
    "costs = costs + myNN.miniBatchRandom(learningRate=0.000001,batchSize=128,batchTimes=300,getCost=True)\n",
    "costs = costs + myNN.miniBatchRandom(learningRate=0.0000001,batchSize=128,batchTimes=300,getCost=True)\n",
    "\n",
    "# 绘制cost函数曲线\n",
    "\n",
    "plt.plot(costs)\n",
    "plt.title('costs')\n",
    "plt.xlabel(\"iteration times\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.show()\n",
    "\n",
    "# 在预测时候，将输入的dropout删除\n",
    "if \"dropout-input\" in myNN.hyperParameters: \n",
    "    print('delete dropout in input')\n",
    "    myNN.hyperParameters.pop('dropout-input')\n",
    "else:\n",
    "    pass\n",
    "\n",
    "trainPre,trainPreBool = myNN.predict(X=trainImage)\n",
    "print('train accuracy:',myNN.accuracy(trainPreBool,trainLabel))\n",
    "\n",
    "testPre,testPreBool = myNN.predict(X=testImage)\n",
    "print('test 1~10000 accuracy:',myNN.accuracy(testPreBool,testLabel))\n",
    "\n",
    "testPre,testPreBool = myNN.predict(X=testImage[:,:5000])\n",
    "print('test 1~5000 accuracy:',myNN.accuracy(testPreBool,testLabel[:,:5000])) # 前5000个样本的正确率\n",
    "\n",
    "testPre,testPreBool = myNN.predict(X=testImage[:,5000:])\n",
    "print('test 5000~10000 accuracy:',myNN.accuracy(testPreBool,testLabel[:,5000:])) # 后5000个样本的正确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测算法正确性(测试用)\n",
    "\n",
    "在作业中保留是因为在写文档的时候，也需要做一些测试，检查的时候可以跳过这里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2boolTuple = lambda l:list(zip(range(10), l)) # list 到二元组（数字，bool），方便查看结果\n",
    "\n",
    "index = 9000 # 选中的测试图片\n",
    "print(\"真实标签:\")\n",
    "print(list2boolTuple(testLabel[:,index]))\n",
    "nowPre,nowPreBool = myNN.predict(X = testImage[:,index].reshape(-1,1))\n",
    "nowImage = testImage[:,index]\n",
    "nowImage = np.array(nowImage) # 创建新数据, 防止数据被改变\n",
    "nowImage = nowImage.reshape(28,28) # 返回图片的原始形状\n",
    "nowImage *= 255 # 恢复为0~255的灰度值\n",
    "nowImage = nowImage.astype(int) # float不支持转为图片, 所以用int\n",
    "\n",
    "plt.imshow(Image.fromarray(nowImage))\n",
    "plt.show()\n",
    "print('-'*30)\n",
    "print(\"预测标签\")\n",
    "print(list2boolTuple(nowPreBool.T.tolist()[0]))\n",
    "print(list2boolTuple(nowPre.T.tolist()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试自己的图片\n",
    "\n",
    "会打开自己本地画的一张名为“number.bmp”的图片\n",
    "\n",
    "然后用训练好的神经网络来看看这个图片应该被归类到哪个数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myNumber = Image.open('number.bmp') # 打开图片,注意图片本身的格式, 如果是256色模式, 就不用将RGB相加了\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(myNumber) # 显示图片\n",
    "plt.title('origin picture')\n",
    "\n",
    "plt.subplot(122)\n",
    "myNumber = myNumber.resize((28,28),Image.ANTIALIAS) # 重置大小, 宽度为28, 高度为28\n",
    "plt.imshow(myNumber) # 显示resize后的图片\n",
    "plt.title('after resize')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "myNumberArr = np.array(myNumber) # 从图片获取 array\n",
    "# print(myNumberArr.shape)\n",
    "\n",
    "# 归一化后才可以predict\n",
    "myNumberArr = myNumberArr / 255\n",
    "myNumberArr = myNumberArr.reshape(28*28,1)\n",
    "myPre,myPreBool = myNN.predict(X=myNumberArr)\n",
    "\n",
    "# print(myPreBool.T)\n",
    "# plt.figure()\n",
    "probablity = (softmax(myPre).T.reshape(10,) * 100).tolist()\n",
    "# print(probablity)\n",
    "preNumber = probablity.index(max(probablity))\n",
    "plt.title(str(preNumber)+' : '+str(round(max(probablity),2))+'%')\n",
    "plt.bar([i for i in range(10)],probablity,[0.5 for i in range(10)], \\\n",
    "        align = 'center')\n",
    "plt.xlabel(\"number\")\n",
    "plt.ylabel(\"probility\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 结果分析\n",
    "\n",
    "### hyperparameters分析\n",
    "\n",
    "我用的参数是, 输入层为784\n",
    "\n",
    "隐层有3层, 分别为500, 300, 200\n",
    "\n",
    "输出层为10\n",
    "\n",
    "L2正则化中的lambda系数为0.001\n",
    "\n",
    "dropout在输入层上为0.9, 在隐层上为0.8\n",
    "\n",
    "### 训练集分析与测试集分析\n",
    "\n",
    "测试集上对于全部总共10000张图片的正确率为`0.9507`\n",
    "对于前5000张图片的正确率为`0.9316`,\n",
    "后5000张图片的正确率为`0.9698`\n",
    "符合在数据描述文档中，前5000张图片较难识别的描述\n",
    "\n",
    "训练集上的正确率为`0.951183333333`\n",
    "\n",
    "训练集和测试集的正确率均为95%左右，方差较大，但是偏差较小(cost相差较小)\n",
    "\n",
    "图片的识别率有待提高, 因为无论在训练集, 还是在测试集上, 识别率都只有95%左右\n",
    "\n",
    "overfitting貌似没有出现\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
